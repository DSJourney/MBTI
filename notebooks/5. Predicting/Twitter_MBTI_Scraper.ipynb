{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter MBTI web scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<p><b>Introduction:</b> using Twitter's API and tweepy (the Python wrapper) we looked for some users who have in their twitter bios the MBTI type they consider themselves to be. After finding these people, we used their screen name to extract 100 of their tweets or as many as they had (without considering re-tweets). This dataset will allow us to then try our models to see how they behave.</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import webbrowser\n",
    "import time\n",
    "import credentials\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This notebook will not work unless you create your own credentials.py file with the consumer_key, consumer_secret. This document has been left out of the repository on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = credentials.Consumer_Key\n",
    "consumer_secret = credentials.Consumer_Secret\n",
    "callback_uri = 'oob' # https://cf.sh/twitter/callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to connect to twitter's service\n",
    "auth = tweepy.OAuthHandler(consumer_key,consumer_secret, callback_uri) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authorize?oauth_token=rFAH3wAAAAABFLRyAAABdY6qF5w\n"
     ]
    }
   ],
   "source": [
    "#will return the url\n",
    "redirect_url = auth.get_authorization_url()\n",
    "print(redirect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open(redirect_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pint_input = input(\"What's the pin value?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these keys do not change (only if you change the consumer key or secret)\n",
    "auth.get_access_token(user_pint_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "me = api.me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we test everything by checking our own twitter account\n",
    "print(me.screen_name)\n",
    "print(me.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(\" \") #include the username in between the brakets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timeline_as_df(user, pages):\n",
    "    user_list = []\n",
    "    for i in range(pages):\n",
    "        user_list.append(user.timeline(page=i))\n",
    "    \n",
    "    columns = set()\n",
    "    allowed_types = [str,int]\n",
    "    tweets_data = []\n",
    "    for timeline_list in user_list:\n",
    "        for status in timeline_list:\n",
    "            #print(status.text)\n",
    "            #print(vars(status))\n",
    "            status_dict = dict(vars(status))\n",
    "            keys = vars(status).keys()\n",
    "            single_tweet_data = {'user': status.user.screen_name, 'author': status.author.screen_name}\n",
    "            for key in keys:\n",
    "                try:\n",
    "                    v_type = type(status_dict[key])\n",
    "                except:\n",
    "                    v_type = None\n",
    "                if v_type != None:\n",
    "                    if v_type in allowed_types:\n",
    "                        single_tweet_data[key] = status_dict[key]\n",
    "                        columns.add(key)\n",
    "\n",
    "            tweets_data.append(single_tweet_data)\n",
    "\n",
    "    header_cols = list(columns)\n",
    "    header_cols.append('user')\n",
    "    header_cols.append('author')\n",
    "\n",
    "    df = pd.DataFrame(tweets_data, columns=header_cols)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user =extract_timeline_as_df(user,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_friends = user.friends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['ISTJ', 'ISFJ', 'INFJ', 'INTJ', 'ISTP', 'ISFP', 'INFP', 'INTP', 'ESTP', 'ESFP', 'ENFP', 'ENTP', 'ESTJ', 'ESFJ', 'ENFJ', 'ENTJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTP LII 9W8\n",
      "\n",
      "YOUTUBE CHANNEL: THE INTROVERTED THINKER\n",
      "\n",
      "ORIGINALLY INTP ACCOUNT (WITH HOBBY LEVEL INTEREST IN WEB DEVELOPMENT), BUT ONE DAY... EVERYTHING CHANGED WHEN I TURNED INTO THE MOON.\n",
      "\n",
      "ENFJ | 2W3 |‚ôåÔ∏é ‚ôàÔ∏é ‚ôãÔ∏é | PSYCHIC BISEXUAL ENERGY | JUNGIAN PERSONALITY THEORY, INDIVIDUATION, SHADOW INTEGRATION, ASTROLOGY | BRAND STRATEGY @NOVASOLISCO\n",
      "\n",
      "LIMINAL\n",
      "\n",
      "INTP 4W3\n",
      "\n",
      "INFJ | IEI-FE | 9W1 SX/SP (945) | H-EDS | ARIES ‚òÄÔ∏è AQUARIUS üåô GEMINI ‚§¥Ô∏è | BLACK LIVES MATTER\n",
      "\n",
      "THERE'S MORE TO¬†TYPE¬†THAN MEETS¬†THE EYE. INFJ \n",
      "CERTIFIED MBTI PRACTITIONER & PHILOSOPHER OF LIFE\n",
      "\n",
      "YOU ARE TERRIFYING AND STRANGE AND BEAUTIFUL, SOMETHING NOT EVERYONE KNOWS HOW TO LOVE ‚Ä¢ ENFP, IEE ‚Ä¢ 4W5, SX/SO, 479 ‚Ä¢ WITCH ‚Ä¢ ‚ôìÔ∏è‚ôèÔ∏è‚ôíÔ∏è\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for friend in user_friends:\n",
    "    tester = any(x in friend.description.upper() for x in types)\n",
    "    if tester == True:\n",
    "        print(friend.description.upper())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Users with MBTI in their description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(\"mbti_insights\") #we find a twitter account whose followers are potential candidates to have an MBTI type in their bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = []\n",
    "\n",
    "c = tweepy.Cursor(api.followers_ids, screen_name='mbti_insights').items(2500)\n",
    "    \n",
    "while True:\n",
    "    try:\n",
    "        follower = c.next()\n",
    "        followers.append(follower)\n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60 * 15)\n",
    "        continue\n",
    "    except StopIteration:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_mbti_insights = {}\n",
    "for follower in followers:\n",
    "    try:\n",
    "        description = any(x in api.get_user(follower).description.upper() for x in types)\n",
    "        if description == True:\n",
    "            followers_mbti_insights[follower] = api.get_user(follower).description\n",
    "            \n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60 * 15)\n",
    "        continue\n",
    "        \n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(\"16Personalities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|‚ñé         | 64/2500 [08:09<5:29:04,  8.11s/it]Rate limit reached. Sleeping for: 375\n",
      " 10%|‚ñâ         | 244/2500 [1:05:52<4:08:45,  6.62s/it] Rate limit reached. Sleeping for: 389\n",
      " 12%|‚ñà‚ñè        | 311/2500 [1:25:44<9:53:44, 16.27s/it]  Rate limit reached. Sleeping for: 101\n",
      " 15%|‚ñà‚ñå        | 375/2500 [1:41:44<5:06:14,  8.65s/it] Rate limit reached. Sleeping for: 37\n",
      " 19%|‚ñà‚ñâ        | 487/2500 [2:30:14<3:01:53,  5.42s/it]   Rate limit reached. Sleeping for: 528\n",
      " 22%|‚ñà‚ñà‚ñè       | 552/2500 [2:45:02<3:04:56,  5.70s/it]  Rate limit reached. Sleeping for: 546\n",
      " 25%|‚ñà‚ñà‚ñç       | 615/2500 [2:59:14<3:12:45,  6.14s/it]  Rate limit reached. Sleeping for: 602\n",
      " 27%|‚ñà‚ñà‚ñã       | 681/2500 [3:13:49<2:28:42,  4.91s/it]  Rate limit reached. Sleeping for: 635\n",
      " 30%|‚ñà‚ñà‚ñâ       | 745/2500 [3:29:17<2:03:22,  4.22s/it]  Rate limit reached. Sleeping for: 611\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 808/2500 [3:43:44<1:54:43,  4.07s/it]  Rate limit reached. Sleeping for: 649\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 874/2500 [3:58:32<1:12:47,  2.69s/it]  Rate limit reached. Sleeping for: 665\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 941/2500 [4:13:45<1:26:58,  3.35s/it]  Rate limit reached. Sleeping for: 659\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 1003/2500 [4:28:53<1:40:19,  4.02s/it] Rate limit reached. Sleeping for: 654\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1067/2500 [4:46:42<2:54:51,  7.32s/it]  Rate limit reached. Sleeping for: 489\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1133/2500 [5:01:36<2:43:07,  7.16s/it]  Rate limit reached. Sleeping for: 497\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1199/2500 [5:16:08<1:34:51,  4.37s/it]  Rate limit reached. Sleeping for: 531\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1262/2500 [16:31:48<1:21:46,  3.96s/it]      Rate limit reached. Sleeping for: 667\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1324/2500 [16:46:14<56:13,  2.87s/it]    Rate limit reached. Sleeping for: 703\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1389/2500 [17:01:15<50:33,  2.73s/it]    Rate limit reached. Sleeping for: 711\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1494/2500 [17:45:35<54:15,  3.24s/it]     Rate limit reached. Sleeping for: 716\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1558/2500 [18:00:42<41:56,  2.67s/it]    Rate limit reached. Sleeping for: 715\n",
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1623/2500 [18:15:36<39:34,  2.71s/it]    Rate limit reached. Sleeping for: 726\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1685/2500 [18:30:52<1:07:12,  4.95s/it]  Rate limit reached. Sleeping for: 713\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1754/2500 [18:46:10<35:38,  2.87s/it]    Rate limit reached. Sleeping for: 701\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1828/2500 [19:00:59<30:11,  2.70s/it]    Rate limit reached. Sleeping for: 717\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1944/2500 [19:44:05<21:31,  2.32s/it]    Rate limit reached. Sleeping for: 716\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 2006/2500 [19:59:04<26:12,  3.18s/it]    Rate limit reached. Sleeping for: 719\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 2069/2500 [20:14:07<20:44,  2.89s/it]    Rate limit reached. Sleeping for: 723\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 2140/2500 [20:52:42<15:02,  2.51s/it]    Rate limit reached. Sleeping for: 729\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2206/2500 [21:07:56<15:52,  3.24s/it]    Rate limit reached. Sleeping for: 720\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2273/2500 [21:22:53<11:41,  3.09s/it]    Rate limit reached. Sleeping for: 727\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2339/2500 [21:37:54<05:40,  2.11s/it]    Rate limit reached. Sleeping for: 730\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2405/2500 [21:53:00<04:13,  2.67s/it]   Rate limit reached. Sleeping for: 731\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2471/2500 [22:08:06<01:28,  3.06s/it]   Rate limit reached. Sleeping for: 730\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [22:21:47<00:00, 32.20s/it]   \n"
     ]
    }
   ],
   "source": [
    "followers_with_mbti = {}\n",
    "for follower in tqdm(followers):\n",
    "    try:\n",
    "        description = any(x in api.get_user(follower).description.upper() for x in types)\n",
    "        if description == True:\n",
    "            followers_with_mbti[follower] = api.get_user(follower).description\n",
    "            \n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60 * 15)\n",
    "        continue\n",
    "        \n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(followers_with_mbti, index=[0]).T.reset_index()\n",
    "df.columns = ['twitter_id','bio']\n",
    "df['types'] = df[\"bio\"].str.upper().str.findall(r\"|\".join(types)).apply(\" \".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFJ                                  166\n",
       "INFP                                  134\n",
       "INTP                                   78\n",
       "ENFP                                   59\n",
       "INTJ                                   59\n",
       "ENTP                                   41\n",
       "ENTJ                                   21\n",
       "ENFJ                                   19\n",
       "ISFJ                                   13\n",
       "ISTP                                   13\n",
       "ISTJ                                   11\n",
       "ISFP                                   11\n",
       "ESTP                                    9\n",
       "ESFP                                    8\n",
       "ESFJ                                    5\n",
       "INFJ INFJ                               4\n",
       "INFP INFP                               3\n",
       "ESTJ                                    3\n",
       "ISFJ ISFJ                               2\n",
       "INFJ INFP                               1\n",
       "INFP ISFP                               1\n",
       "ISFJ INTP                               1\n",
       "INTJ INTP                               1\n",
       "INFJ ESFJ                               1\n",
       "INFP ESTJ                               1\n",
       "INFJ INFJ INFJ                          1\n",
       "INFP INTP                               1\n",
       "ENTP ENTP                               1\n",
       "ISFP ESTJ                               1\n",
       "INFJ ENFJ                               1\n",
       "INFP INFP INFP                          1\n",
       "ESFP ENTJ                               1\n",
       "INFJ ENTJ ENFJ INFJ                     1\n",
       "ISTJ ISTJ                               1\n",
       "INFP INFP INFP INFP INFP INFP INFP      1\n",
       "INTP ISTP                               1\n",
       "ENTJ ENTJ ENTJ                          1\n",
       "ENFP ISFJ                               1\n",
       "INFJ ISTP                               1\n",
       "ENFP INTJ                               1\n",
       "ENTJ INTJ                               1\n",
       "INFJ INFJ INFJ INFJ INFJ                1\n",
       "INTP INFJ                               1\n",
       "ESFJ ENTJ                               1\n",
       "ENFP ENFJ                               1\n",
       "ENTP ISTJ                               1\n",
       "INTJ INFP                               1\n",
       "Name: types, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_types = []\n",
    "for i in df['types']:\n",
    "    words = i.split()\n",
    "    mbti_type = \" \".join(sorted(set(words), key=words.index))\n",
    "    corrected_types.append(mbti_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['types'] = corrected_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().strftime('%Y_%m_%d')\n",
    "df.to_csv('twitter_users/results_'+today+'.csv', index=0, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_followers(user=user, number_followers=2500):\n",
    "    \n",
    "    followers_list = []\n",
    "\n",
    "    c = tweepy.Cursor(api.followers_ids, screen_name=user).items(number_followers)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            follower = c.next()\n",
    "            followers_list.append(follower)\n",
    "        except tweepy.TweepError:\n",
    "            time.sleep(60 * 15)\n",
    "            continue\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "    return followers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_descriptions(list_followers):\n",
    "    \n",
    "    dict_user_description = {}\n",
    "    \n",
    "    for follower in tqdm(list_followers):\n",
    "        try:\n",
    "            description = any(x in api.get_user(follower).description.upper() for x in types)\n",
    "            if description == True:\n",
    "                dict_user_description[follower] = api.get_user(follower).description\n",
    "\n",
    "        except tweepy.TweepError:\n",
    "            time.sleep(60 * 15)\n",
    "            continue\n",
    "\n",
    "        except StopIteration:\n",
    "            break\n",
    "            \n",
    "    return dict_user_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of followers 4000\n",
      "Followers minus already analyze 3918\n"
     ]
    }
   ],
   "source": [
    "user = \"mbtitime\"\n",
    "\n",
    "followers_list = extract_followers(user=user, number_followers=4000)\n",
    "print('Total number of followers', len(followers_list))\n",
    "res = [i for i in followers_list if i not in df.twitter_id.to_list()]\n",
    "print('Followers minus already analyzed', len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 63/3918 [04:18<3:56:01,  3.67s/it]Rate limit reached. Sleeping for: 638\n",
      "  3%|‚ñé         | 123/3918 [19:14<3:40:54,  3.49s/it]  Rate limit reached. Sleeping for: 649\n",
      "  5%|‚ñç         | 182/3918 [34:16<3:25:00,  3.29s/it]   Rate limit reached. Sleeping for: 651\n",
      "  6%|‚ñå         | 242/3918 [49:26<3:58:09,  3.89s/it]   Rate limit reached. Sleeping for: 646\n",
      "  8%|‚ñä         | 304/3918 [1:04:21<3:31:40,  3.51s/it]   Rate limit reached. Sleeping for: 657\n",
      "  9%|‚ñâ         | 363/3918 [1:19:26<4:34:55,  4.64s/it]   Rate limit reached. Sleeping for: 654\n",
      " 11%|‚ñà         | 422/3918 [1:35:24<4:44:29,  4.88s/it]   Rate limit reached. Sleeping for: 600\n",
      " 12%|‚ñà‚ñè        | 484/3918 [1:49:54<3:26:43,  3.61s/it]   Rate limit reached. Sleeping for: 637\n",
      " 14%|‚ñà‚ñç        | 545/3918 [2:05:02<3:44:41,  4.00s/it]   Rate limit reached. Sleeping for: 635\n",
      " 16%|‚ñà‚ñå        | 611/3918 [2:20:49<4:20:12,  4.72s/it]   Rate limit reached. Sleeping for: 594\n",
      " 17%|‚ñà‚ñã        | 671/3918 [2:35:59<5:21:01,  5.93s/it]   Rate limit reached. Sleeping for: 586\n",
      " 19%|‚ñà‚ñä        | 733/3918 [2:50:52<4:22:21,  4.94s/it]   Rate limit reached. Sleeping for: 605\n",
      " 20%|‚ñà‚ñà        | 793/3918 [3:06:44<5:05:12,  5.86s/it]   Rate limit reached. Sleeping for: 556\n",
      " 22%|‚ñà‚ñà‚ñè       | 852/3918 [3:20:53<5:27:48,  6.42s/it]   Rate limit reached. Sleeping for: 612\n",
      " 23%|‚ñà‚ñà‚ñé       | 914/3918 [3:36:27<3:58:41,  4.77s/it]   Rate limit reached. Sleeping for: 581\n",
      " 25%|‚ñà‚ñà‚ñç       | 976/3918 [3:52:02<4:55:06,  6.02s/it]   Rate limit reached. Sleeping for: 545\n",
      " 26%|‚ñà‚ñà‚ñã       | 1036/3918 [4:08:46<6:40:06,  8.33s/it]  Rate limit reached. Sleeping for: 445\n",
      " 28%|‚ñà‚ñà‚ñä       | 1101/3918 [4:22:49<5:38:29,  7.21s/it]   Rate limit reached. Sleeping for: 516\n",
      " 30%|‚ñà‚ñà‚ñâ       | 1161/3918 [4:37:30<5:04:49,  6.63s/it]   Rate limit reached. Sleeping for: 539\n",
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 1226/3918 [4:52:14<3:59:22,  5.34s/it]   Rate limit reached. Sleeping for: 562\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 1287/3918 [5:06:59<4:54:09,  6.71s/it]   Rate limit reached. Sleeping for: 583\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 1347/3918 [5:21:09<2:53:52,  4.06s/it]   Rate limit reached. Sleeping for: 640\n",
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 1515/3918 [6:17:36<3:58:31,  5.96s/it]   Rate limit reached. Sleeping for: 483\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 1576/3918 [6:32:27<2:41:59,  4.15s/it]   Rate limit reached. Sleeping for: 496\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1695/3918 [7:09:16<3:35:38,  5.82s/it]   Rate limit reached. Sleeping for: 465\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1754/3918 [7:23:40<4:10:53,  6.96s/it]  Rate limit reached. Sleeping for: 500\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1814/3918 [7:38:57<4:03:44,  6.95s/it]  Rate limit reached. Sleeping for: 490\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1871/3918 [7:54:07<3:56:21,  6.93s/it]  Rate limit reached. Sleeping for: 484\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1934/3918 [8:09:02<4:00:41,  7.28s/it]  Rate limit reached. Sleeping for: 496\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1994/3918 [16:35:41<2:33:32,  4.79s/it]     Rate limit reached. Sleeping for: 615\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2052/3918 [16:50:31<2:48:27,  5.42s/it]   Rate limit reached. Sleeping for: 629\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 2110/3918 [17:05:53<2:22:49,  4.74s/it]   Rate limit reached. Sleeping for: 608\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2167/3918 [17:21:01<2:53:24,  5.94s/it]  Rate limit reached. Sleeping for: 611\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 2225/3918 [17:35:49<2:08:31,  4.56s/it]  Rate limit reached. Sleeping for: 627\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 2284/3918 [17:51:08<2:22:09,  5.22s/it]  Rate limit reached. Sleeping for: 615\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 2341/3918 [18:06:30<1:59:53,  4.56s/it]  Rate limit reached. Sleeping for: 596\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 2401/3918 [18:21:15<1:41:24,  4.01s/it]  Rate limit reached. Sleeping for: 617\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 2461/3918 [18:36:17<1:37:07,  4.00s/it]  Rate limit reached. Sleeping for: 618\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 2520/3918 [18:52:01<1:50:32,  4.74s/it]  Rate limit reached. Sleeping for: 580\n",
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 2579/3918 [19:06:47<1:38:38,  4.42s/it]  Rate limit reached. Sleeping for: 598\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2641/3918 [19:21:50<1:37:27,  4.58s/it]  Rate limit reached. Sleeping for: 602\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 2701/3918 [19:37:26<1:46:11,  5.24s/it]  Rate limit reached. Sleeping for: 572\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 2758/3918 [19:52:45<1:26:10,  4.46s/it]  Rate limit reached. Sleeping for: 555\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 2817/3918 [20:06:46<1:44:03,  5.67s/it]  Rate limit reached. Sleeping for: 616\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 2878/3918 [20:22:47<1:33:02,  5.37s/it]  Rate limit reached. Sleeping for: 562\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 2937/3918 [20:38:16<1:32:00,  5.63s/it]  Rate limit reached. Sleeping for: 540\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 2998/3918 [20:51:41<1:06:43,  4.35s/it]  Rate limit reached. Sleeping for: 642\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3057/3918 [21:07:17<1:26:09,  6.00s/it]  Rate limit reached. Sleeping for: 610\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3119/3918 [21:22:57<1:13:34,  5.53s/it]  Rate limit reached. Sleeping for: 574\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3181/3918 [21:37:08<54:36,  4.45s/it]    Rate limit reached. Sleeping for: 627\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3242/3918 [21:52:48<46:48,  4.16s/it]    Rate limit reached. Sleeping for: 597\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3302/3918 [22:07:39<48:38,  4.74s/it]    Rate limit reached. Sleeping for: 610\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3362/3918 [22:22:24<41:15,  4.45s/it]    Rate limit reached. Sleeping for: 630\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3422/3918 [22:38:10<36:33,  4.42s/it]    Rate limit reached. Sleeping for: 588\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3481/3918 [22:52:50<29:02,  3.99s/it]    Rate limit reached. Sleeping for: 611\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3540/3918 [23:09:24<31:51,  5.06s/it]    Rate limit reached. Sleeping for: 523\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3598/3918 [23:22:53<23:35,  4.42s/it]    Rate limit reached. Sleeping for: 620\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 3657/3918 [23:38:17<24:43,  5.68s/it]    Rate limit reached. Sleeping for: 599\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3734/3918 [24:08:57<11:40,  3.81s/it]    Rate limit reached. Sleeping for: 633\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3795/3918 [24:24:34<12:13,  5.96s/it]   Rate limit reached. Sleeping for: 603\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3858/3918 [24:39:16<04:24,  4.41s/it]   Rate limit reached. Sleeping for: 626\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3918/3918 [24:54:11<00:00, 22.88s/it]   \n"
     ]
    }
   ],
   "source": [
    "dict_descriptions = extract_descriptions(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(dictionary_to_convert):\n",
    "    \"\"\"Converts dictionary into pandas dataframe with renamed columns\"\"\"\n",
    "    df1 = pd.DataFrame(dictionary_to_convert, index=[0]).T.reset_index()\n",
    "    df1.columns = ['twitter_id','bio']\n",
    "    df1['types'] = df1[\"bio\"].str.upper().str.findall(r\"|\".join(types)).apply(\" \".join)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mbti_types(dataframe, column):\n",
    "    \"\"\"Some twitter descriptions have repeated mbti types, this converts them into one\"\"\"\n",
    "    corrected_types = []\n",
    "    for i in dataframe[column]:\n",
    "        words = i.split()\n",
    "        mbti_type = \" \".join(sorted(set(words), key=words.index))\n",
    "        corrected_types.append(mbti_type)\n",
    "    return corrected_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbtitime = create_dataframe(dict_descriptions)\n",
    "df_mbtitime['types'] = clean_mbti_types(dataframe=df_mbtitime, column=\"types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().strftime('%Y_%m_%d')\n",
    "df_mbtitime.to_csv('twitter_users/results_'+today+'.csv', index=0, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting tweets from selected users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['user','name','tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets(twitter_user):\n",
    "    row = {}\n",
    "    row = {}\n",
    "    user = api.get_user(twitter_user)\n",
    "    row['user'] = user.id\n",
    "    row['name'] = user.screen_name\n",
    "    pages = tweepy.Cursor(api.user_timeline, screen_name=row['name'],include_rts=False).items(100)\n",
    "\n",
    "    tweets = []\n",
    "    for page in pages:\n",
    "        tweets.append(page.text)\n",
    "\n",
    "    row['tweets'] = ' ||| '.join(tweets)\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 687/687 [23:22:46<00:00, 122.51s/it]    \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df['twitter_id'].to_list()):\n",
    "    try:\n",
    "        data = data.append(extract_tweets(i), ignore_index=True)\n",
    "    \n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60 * 15)\n",
    "        continue\n",
    "        \n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().strftime('%Y_%m_%d')\n",
    "data.to_csv('tweets_from_users/tweets_'+today+'.csv', index=0, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 550/550 [39:17:29<00:00, 257.18s/it]      \n"
     ]
    }
   ],
   "source": [
    "df_mbtitime_tweets = pd.DataFrame(columns=['user','name','tweets'])\n",
    "\n",
    "for i in tqdm(df_mbtitime['twitter_id'].to_list()):\n",
    "    try:\n",
    "        df_mbtitime_tweets = df_mbtitime_tweets.append(extract_tweets(i), ignore_index=True)\n",
    "    \n",
    "    except tweepy.TweepError:\n",
    "        time.sleep(60 * 15)\n",
    "        continue\n",
    "        \n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().strftime('%Y_%m_%d')\n",
    "df_mbtitime_tweets.to_csv('tweets_from_users/tweets_'+today+'.csv', index=0, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
